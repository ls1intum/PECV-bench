{
  "benchmark": "pecv-reference",
  "generated_at": "2025-12-14T12:53:56.107343+00:00",
  "dataset_summary": {
    "variants_per_course": {
      "ITP2425": {
        "H01E01-Lectures": 30,
        "H02E02-Panic_at_Seal_Saloon": 29,
        "H05E01-Space_Seal_Farm": 32
      }
    },
    "variants_per_exercise": {
      "ITP2425/H01E01-Lectures": 30,
      "ITP2425/H02E02-Panic_at_Seal_Saloon": 29,
      "ITP2425/H05E01-Space_Seal_Farm": 32
    },
    "total_annotated_variants": 91,
    "total_issues": 93,
    "issues_per_category": {
      "VISIBILITY_MISMATCH": 12,
      "METHOD_RETURN_TYPE_MISMATCH": 19,
      "IDENTIFIER_NAMING_INCONSISTENCY": 23,
      "ATTRIBUTE_TYPE_MISMATCH": 17,
      "METHOD_PARAMETER_MISMATCH": 12,
      "CONSTRUCTOR_PARAMETER_MISMATCH": 10
    },
    "issues_per_artifact": {
      "PROBLEM_STATEMENT": 89,
      "SOLUTION_REPOSITORY": 90,
      "TEMPLATE_REPOSITORY": 40
    },
    "injection_analysis": {
      "repositories_affected": {
        "solution": 43,
        "problem_statement": 29,
        "template": 22
      },
      "file_types_affected": {
        "java": 98,
        "markdown": 29
      },
      "injection_patterns": {
        "solution_only": 40,
        "problem_statement_only": 29,
        "template_only": 19,
        "solution_template": 3
      },
      "total_changes": {
        "additions": 578,
        "deletions": 453,
        "modifications": 450,
        "files_changed": 127
      },
      "avg_changes_per_variant": {
        "additions": 6.351648351648351,
        "deletions": 4.978021978021978,
        "modifications": 4.945054945054945,
        "files_changed": 1.3956043956043955
      }
    }
  },
  "runs": [
    {
      "benchmark": "pecv-reference",
      "model": "openai:gpt-5-mini",
      "config_key": "pecv-reference :: model=openai:gpt-5-mini, reasoning_effort=medium",
      "n_runs": 3,
      "totals": {
        "cases": 273,
        "evaluated_cases": 273,
        "tp": 262,
        "fp": 197,
        "fn": 17,
        "matches": 262,
        "precision": 0.5708061002178649,
        "recall": 0.9390681003584229,
        "f1": 0.7100271002710027
      },
      "averages": {
        "span_f1": 0.4333366688772302,
        "iou": 0.3075200332081934,
        "time_s": 31.63427657509158,
        "cost_usd": null
      }
    },
    {
      "benchmark": "pecv-reference",
      "model": "openai:o4-mini",
      "config_key": "pecv-reference :: model=openai:o4-mini, reasoning_effort=medium",
      "n_runs": 3,
      "totals": {
        "cases": 273,
        "evaluated_cases": 273,
        "tp": 254,
        "fp": 148,
        "fn": 25,
        "matches": 254,
        "precision": 0.6318407960199005,
        "recall": 0.910394265232975,
        "f1": 0.7459618208516887
      },
      "averages": {
        "span_f1": 0.6755057392241225,
        "iou": 0.5651832151248483,
        "time_s": 32.95784249084249,
        "cost_usd": 0.033819571428571435
      }
    },
    {
      "benchmark": "pecv-reference",
      "model": "openrouter:google/gemini-2.5-flash",
      "config_key": "pecv-reference :: model=openrouter:google/gemini-2.5-flash, reasoning_effort=medium",
      "n_runs": 3,
      "totals": {
        "cases": 272,
        "evaluated_cases": 272,
        "tp": 263,
        "fp": 623,
        "fn": 15,
        "matches": 263,
        "precision": 0.29683972911963885,
        "recall": 0.9460431654676259,
        "f1": 0.45189003436426123
      },
      "averages": {
        "span_f1": 0.5967519460680862,
        "iou": 0.4740115178558968,
        "time_s": 26.380444852941174,
        "cost_usd": 0.024406463235294124
      }
    },
    {
      "benchmark": "pecv-reference",
      "model": "openrouter:google/gemini-2.5-flash-lite-preview-06-17",
      "config_key": "pecv-reference :: model=openrouter:google/gemini-2.5-flash-lite-preview-06-17, reasoning_effort=medium",
      "n_runs": 3,
      "totals": {
        "cases": 231,
        "evaluated_cases": 231,
        "tp": 216,
        "fp": 288,
        "fn": 21,
        "matches": 216,
        "precision": 0.42857142857142855,
        "recall": 0.9113924050632911,
        "f1": 0.582995951417004
      },
      "averages": {
        "span_f1": 0.5938186300925338,
        "iou": 0.48534255745406807,
        "time_s": 16.97496969696969,
        "cost_usd": 0.006328454545454544
      }
    },
    {
      "benchmark": "pecv-reference",
      "model": "openrouter:x-ai/grok-3-mini",
      "config_key": "pecv-reference :: model=openrouter:x-ai/grok-3-mini, reasoning_effort=medium",
      "n_runs": 3,
      "totals": {
        "cases": 273,
        "evaluated_cases": 273,
        "tp": 233,
        "fp": 222,
        "fn": 46,
        "matches": 233,
        "precision": 0.512087912087912,
        "recall": 0.8351254480286738,
        "f1": 0.6348773841961853
      },
      "averages": {
        "span_f1": 0.6399876331019414,
        "iou": 0.5339039333464974,
        "time_s": 14.30568498168498,
        "cost_usd": 0.006088326007326006
      }
    }
  ],
  "per_exercise": {
    "pecv-reference :: model=openrouter:google/gemini-2.5-flash-lite-preview-06-17, reasoning_effort=medium": {
      "model": "openrouter:google/gemini-2.5-flash-lite-preview-06-17",
      "exercises": [
        {
          "exercise": "ITP2425/H01E01-Lectures",
          "totals": {
            "cases": 78,
            "evaluated_cases": 78,
            "tp": 72,
            "fp": 81,
            "fn": 6,
            "matches": 72,
            "precision": 0.47058823529411764,
            "recall": 0.9230769230769231,
            "f1": 0.6233766233766235
          },
          "averages": {
            "span_f1": 0.6036074900045487,
            "iou": 0.46655413116168926,
            "time_s": 15.18003846153846,
            "cost_usd": 0.004924961538461539
          }
        },
        {
          "exercise": "ITP2425/H02E02-Panic_at_Seal_Saloon",
          "totals": {
            "cases": 72,
            "evaluated_cases": 72,
            "tp": 66,
            "fp": 54,
            "fn": 6,
            "matches": 66,
            "precision": 0.55,
            "recall": 0.9166666666666666,
            "f1": 0.6874999999999999
          },
          "averages": {
            "span_f1": 0.6918582314972689,
            "iou": 0.6041895803558484,
            "time_s": 18.680888888888887,
            "cost_usd": 0.007678083333333332
          }
        },
        {
          "exercise": "ITP2425/H05E01-Space_Seal_Farm",
          "totals": {
            "cases": 81,
            "evaluated_cases": 81,
            "tp": 78,
            "fp": 153,
            "fn": 9,
            "matches": 78,
            "precision": 0.33766233766233766,
            "recall": 0.896551724137931,
            "f1": 0.49056603773584906
          },
          "averages": {
            "span_f1": 0.5018261736005133,
            "iou": 0.402122854653219,
            "time_s": 17.187049382716047,
            "cost_usd": 0.006480296296296296
          }
        }
      ]
    },
    "pecv-reference :: model=openrouter:google/gemini-2.5-flash, reasoning_effort=medium": {
      "model": "openrouter:google/gemini-2.5-flash",
      "exercises": [
        {
          "exercise": "ITP2425/H01E01-Lectures",
          "totals": {
            "cases": 90,
            "evaluated_cases": 90,
            "tp": 87,
            "fp": 123,
            "fn": 3,
            "matches": 87,
            "precision": 0.4142857142857143,
            "recall": 0.9666666666666667,
            "f1": 0.5800000000000001
          },
          "averages": {
            "span_f1": 0.6551004986049507,
            "iou": 0.5274915944324985,
            "time_s": 20.255788888888887,
            "cost_usd": 0.017615666666666665
          }
        },
        {
          "exercise": "ITP2425/H02E02-Panic_at_Seal_Saloon",
          "totals": {
            "cases": 86,
            "evaluated_cases": 86,
            "tp": 86,
            "fp": 104,
            "fn": 0,
            "matches": 86,
            "precision": 0.45263157894736844,
            "recall": 1.0,
            "f1": 0.6231884057971014
          },
          "averages": {
            "span_f1": 0.5783351013024146,
            "iou": 0.4674188104038613,
            "time_s": 25.32740697674419,
            "cost_usd": 0.026043651162790702
          }
        },
        {
          "exercise": "ITP2425/H05E01-Space_Seal_Farm",
          "totals": {
            "cases": 96,
            "evaluated_cases": 96,
            "tp": 90,
            "fp": 396,
            "fn": 12,
            "matches": 90,
            "precision": 0.18518518518518517,
            "recall": 0.8823529411764706,
            "f1": 0.3061224489795918
          },
          "averages": {
            "span_f1": 0.557946663614093,
            "iou": 0.4286138087304607,
            "time_s": 33.065656249999996,
            "cost_usd": 0.029306187499999987
          }
        }
      ]
    },
    "pecv-reference :: model=openai:gpt-5-mini, reasoning_effort=medium": {
      "model": "openai:gpt-5-mini",
      "exercises": [
        {
          "exercise": "ITP2425/H01E01-Lectures",
          "totals": {
            "cases": 90,
            "evaluated_cases": 90,
            "tp": 82,
            "fp": 44,
            "fn": 8,
            "matches": 82,
            "precision": 0.6507936507936508,
            "recall": 0.9111111111111111,
            "f1": 0.7592592592592592
          },
          "averages": {
            "span_f1": 0.48709850462936277,
            "iou": 0.35661455021011296,
            "time_s": 23.466093033333337,
            "cost_usd": null
          }
        },
        {
          "exercise": "ITP2425/H02E02-Panic_at_Seal_Saloon",
          "totals": {
            "cases": 87,
            "evaluated_cases": 87,
            "tp": 82,
            "fp": 82,
            "fn": 5,
            "matches": 82,
            "precision": 0.5,
            "recall": 0.9425287356321839,
            "f1": 0.6533864541832669
          },
          "averages": {
            "span_f1": 0.41286209758453973,
            "iou": 0.29873742095156447,
            "time_s": 35.530130885057474,
            "cost_usd": null
          }
        },
        {
          "exercise": "ITP2425/H05E01-Space_Seal_Farm",
          "totals": {
            "cases": 96,
            "evaluated_cases": 96,
            "tp": 98,
            "fp": 71,
            "fn": 4,
            "matches": 98,
            "precision": 0.5798816568047337,
            "recall": 0.9607843137254902,
            "f1": 0.7232472324723247
          },
          "averages": {
            "span_f1": 0.40548405983973806,
            "iou": 0.2737896639315217,
            "time_s": 35.76133067708333,
            "cost_usd": null
          }
        }
      ]
    },
    "pecv-reference :: model=openai:o4-mini, reasoning_effort=medium": {
      "model": "openai:o4-mini",
      "exercises": [
        {
          "exercise": "ITP2425/H01E01-Lectures",
          "totals": {
            "cases": 90,
            "evaluated_cases": 90,
            "tp": 80,
            "fp": 32,
            "fn": 10,
            "matches": 80,
            "precision": 0.7142857142857143,
            "recall": 0.8888888888888888,
            "f1": 0.792079207920792
          },
          "averages": {
            "span_f1": 0.7061973326415462,
            "iou": 0.5886668427569163,
            "time_s": 27.805177777777775,
            "cost_usd": 0.0250572
          }
        },
        {
          "exercise": "ITP2425/H02E02-Panic_at_Seal_Saloon",
          "totals": {
            "cases": 87,
            "evaluated_cases": 87,
            "tp": 80,
            "fp": 46,
            "fn": 7,
            "matches": 80,
            "precision": 0.6349206349206349,
            "recall": 0.9195402298850575,
            "f1": 0.7511737089201878
          },
          "averages": {
            "span_f1": 0.6645303171780779,
            "iou": 0.573595069651572,
            "time_s": 32.697954022988505,
            "cost_usd": 0.03975922988505747
          }
        },
        {
          "exercise": "ITP2425/H05E01-Space_Seal_Farm",
          "totals": {
            "cases": 96,
            "evaluated_cases": 96,
            "tp": 94,
            "fp": 70,
            "fn": 8,
            "matches": 94,
            "precision": 0.573170731707317,
            "recall": 0.9215686274509803,
            "f1": 0.7067669172932329
          },
          "averages": {
            "span_f1": 0.658726018908056,
            "iou": 0.5380381239258766,
            "time_s": 38.02398958333333,
            "cost_usd": 0.036651479166666674
          }
        }
      ]
    },
    "pecv-reference :: model=openrouter:x-ai/grok-3-mini, reasoning_effort=medium": {
      "model": "openrouter:x-ai/grok-3-mini",
      "exercises": [
        {
          "exercise": "ITP2425/H01E01-Lectures",
          "totals": {
            "cases": 90,
            "evaluated_cases": 90,
            "tp": 78,
            "fp": 38,
            "fn": 12,
            "matches": 78,
            "precision": 0.6724137931034483,
            "recall": 0.8666666666666667,
            "f1": 0.7572815533980582
          },
          "averages": {
            "span_f1": 0.6292599500690713,
            "iou": 0.504436951099847,
            "time_s": 11.939733333333333,
            "cost_usd": 0.004709055555555555
          }
        },
        {
          "exercise": "ITP2425/H02E02-Panic_at_Seal_Saloon",
          "totals": {
            "cases": 87,
            "evaluated_cases": 87,
            "tp": 71,
            "fp": 58,
            "fn": 16,
            "matches": 71,
            "precision": 0.5503875968992248,
            "recall": 0.8160919540229885,
            "f1": 0.6574074074074074
          },
          "averages": {
            "span_f1": 0.6288534036784429,
            "iou": 0.5418329441076503,
            "time_s": 17.109344827586206,
            "cost_usd": 0.007386310344827586
          }
        },
        {
          "exercise": "ITP2425/H05E01-Space_Seal_Farm",
          "totals": {
            "cases": 96,
            "evaluated_cases": 96,
            "tp": 84,
            "fp": 126,
            "fn": 18,
            "matches": 84,
            "precision": 0.4,
            "recall": 0.8235294117647058,
            "f1": 0.5384615384615384
          },
          "averages": {
            "span_f1": 0.6593601279308974,
            "iou": 0.5545642291940795,
            "time_s": 13.982947916666667,
            "cost_usd": 0.006205093749999999
          }
        }
      ]
    }
  }
}